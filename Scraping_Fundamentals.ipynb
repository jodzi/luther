{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the HTML from a page, and convert to a BeautifulSoup object\n",
    "#### We'll start by scraping some information from Box Office Mojo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib2\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Own Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_soup_page(url):\n",
    "    \"\"\"\n",
    "    builds a beautifulsoup object from a url\n",
    "    \"\"\"\n",
    "    page = urllib2.urlopen(url)\n",
    "    soup = BeautifulSoup(page) \n",
    "                         #'xml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_top_index(soup, to_search, beg_url):\n",
    "    \"\"\"\n",
    "    builds an index from a soup object with a search string\n",
    "    \"\"\"\n",
    "    \n",
    "    index = []\n",
    "    \n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if a['href'].startswith(to_search):\n",
    "            index.append(beg_url + a['href'])\n",
    "    end_index = len(index) / 2\n",
    "    \n",
    "    return index[:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_sub_index(soup, search_one, search_two, beg_url):\n",
    "    \"\"\"\n",
    "    builds an index from a soup object with a search and count string\n",
    "    \"\"\"\n",
    "    \n",
    "    index = []\n",
    "    \n",
    "    for a in soup.find_all('a', href=True):\n",
    "        if a['href'].startswith(search_one) and re.search(search_two, a['href']) != None:\n",
    "            index.append(beg_url + a['href'])\n",
    "    end_index = len(index) / 2\n",
    "    \n",
    "    return index[:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_single_movie_url_list(total_urls, box_url):\n",
    "    \"\"\"\n",
    "    builds a list of every movies url\n",
    "    \"\"\"\n",
    "    \n",
    "    single_movie_url_tags = []\n",
    "\n",
    "    for full_site in total_urls:\n",
    "        soup = build_soup_page(full_site)\n",
    "        for a in soup.find_all('a', href=True):\n",
    "            if re.search('id', a['href']) != None and a['href'] not in single_movie_url_tags:\n",
    "                single_movie_url_tags.append(box_url + a['href'])   \n",
    "    return set(single_movie_url_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Build soup document and build index of movies pages from A-Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# creates a soup object containing the href for all pages A-Z & NUM\n",
    "movie_pages_az_level = build_soup_page(\"http://www.boxofficemojo.com/movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# builds a list of each url ending for NUM and A-Z movie pages\n",
    "movie_pages_az_urls = build_top_index(movie_pages_az_level, 'alphabetical', \"http://www.boxofficemojo.com/movies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#movie_pages_az_urls[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build sub level pages for each letter of title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Builds total urls for all pages of movies\n",
    "total_urls = movie_pages_az_urls[:]\n",
    "\n",
    "for movie_page in movie_pages_az_urls:\n",
    "    top_level_soup = build_soup_page(movie_page)\n",
    "    sub_level = build_sub_index(top_level_soup, '/movies/', 'page', \"http://www.boxofficemojo.com\")\n",
    "    if len(sub_level) > 0:\n",
    "        for sub_level_url in sub_level:\n",
    "            if sub_level_url.count('id') == 0:\n",
    "                total_urls.append(sub_level_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=10&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=2&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=3&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=4&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=5&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=6&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=7&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=8&p=.htm',\n",
       " 'http://www.boxofficemojo.com/movies/alphabetical.htm?letter=A&page=9&p=.htm']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(total_urls)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to loop through and filter out urls that have foreign pages and have u.k. values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#movie_urls\n",
    "#single_movies_A = build_single_movie_url_list([total_urls[1]], 'http://www.boxofficemojo.com')\n",
    "#for url in sorted(total_urls)[0:10]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#single_movies_A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing on a single movie page if there is a foreign page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = build_soup_page('http://www.boxofficemojo.com/movies/?id=ateam.htm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action\n"
     ]
    }
   ],
   "source": [
    "test_list2 = []\n",
    "#print test.find(attrs={'valign': re.compile('Genre')})\n",
    "print str(test.find(text = re.compile('Genre: ')).findNextSibling().text)\n",
    "#test_val = str(obj.findNextSibling().text)\n",
    "#test_val == 'Action'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for movie in list(single_movies_A):\n",
    "    movie_soup = build_soup_page(movie)\n",
    "    if movie_soup.find(attrs={'href': re.compile('page=intl')}) != None and \\\n",
    "                            str(movie_soup.find(text = re.compile('Genre: ')).findNextSibling().text) != 'Foreign':\n",
    "        test_list.append(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of urls in test_list are the movies that aren't foreign but have an international page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for url in sorted(test_list):\n",
    "#    print url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle (save a file) of things as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def store_pickles(filename, to_store):\n",
    "    with open(filename, 'w') as f:\n",
    "        pickle.dump(to_store, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eat_pickles(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jar_of_pickles = eat_pickles('page_data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#jar_of_pickles['http://www.boxofficemojo.com/movies/?id=ateam.htm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dictionary of actor name as key, number of movies as value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_names = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actor_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for el in sub_people_one.findAll(align='right'):\n",
    "    if re.search('\\$', el.text) == None:\n",
    "        actor_data.append(el.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#actor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_actor_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for a in test2.find_all('a', href=True):\n",
    "    if a['href'].startswith('./chart/?view'): \n",
    "        new_actor_data.append(a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start building data structure of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_movie_value(soup, field_name):\n",
    "    \"\"\"\n",
    "    takes a string attribute of a movie on the page, and returns the string in the next\n",
    "    sibling object (the value for that attritube)\n",
    "    \"\"\"\n",
    "    obj = soup.find(text = re.compile(field_name))\n",
    "    if not obj:\n",
    "        return None\n",
    "    next_sibling = obj.findNextSibling()\n",
    "    if next_sibling:\n",
    "        return next_sibling.text\n",
    "    else:\n",
    "        return None  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "\n",
    "for movie in single_movies[:1000]:\n",
    "    try:\n",
    "        soup = build_soup_page(movie)\n",
    "    except:\n",
    "        continue\n",
    "    dtg = get_movie_value(soup, \"Domestic Total\")\n",
    "    runtime = get_movie_value(soup, \"Runtime\")\n",
    "    rating = get_movie_value(soup, \"MPAA Rating\")\n",
    "    release_date = get_movie_value(soup, \"Release Date\")\n",
    "    test.append([dtg, runtime, rating, release_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for el in test:\n",
    "#    print el"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
